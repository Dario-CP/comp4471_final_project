{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "gUamXr1linmg"
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "gpuClass": "standard",
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bs07TZlH_F3r",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!nvidia-smi"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SmPly3L2EHHG",
    "outputId": "8fc824ef-8ab3-4399-dcce-c8352e9ec3f6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov 17 19:22:38 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 522.25       Driver Version: 522.25       CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   47C    P8     9W /  N/A |   7386MiB /  8192MiB |      5%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1100    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A      3692    C+G   ...4__8j3eq9eme6ctt\\IGCC.exe    N/A      |\n",
      "|    0   N/A  N/A      5100    C+G   ...tz\\RAT8\\RAT8_Profiler.exe    N/A      |\n",
      "|    0   N/A  N/A      6152    C+G   ...bin\\jetbrains-toolbox.exe    N/A      |\n",
      "|    0   N/A  N/A      6600    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A      7712    C+G   ...qxf38zg5c\\Skype\\Skype.exe    N/A      |\n",
      "|    0   N/A  N/A     10348    C+G   ...7\\jbr\\bin\\jcef_helper.exe    N/A      |\n",
      "|    0   N/A  N/A     12024    C+G   ...er_engine\\wallpaper32.exe    N/A      |\n",
      "|    0   N/A  N/A     13080    C+G   ...8wekyb3d8bbwe\\Cortana.exe    N/A      |\n",
      "|    0   N/A  N/A     15776    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     16228    C+G   ...ge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     16796    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     17804      C   ...nal_project_cv\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     19148    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "|    0   N/A  N/A     23144    C+G   ...in7x64\\steamwebhelper.exe    N/A      |\n",
      "|    0   N/A  N/A     23892    C+G   ...e\\PhoneExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     24376    C+G   ...qxf38zg5c\\Skype\\Skype.exe    N/A      |\n",
      "|    0   N/A  N/A     24476    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     29364    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     29692    C+G   ...8wekyb3d8bbwe\\GameBar.exe    N/A      |\n",
      "|    0   N/A  N/A     29704    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     30604    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     32088    C+G   ...kzcwy\\mcafee-security.exe    N/A      |\n",
      "|    0   N/A  N/A     32740    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from dataset_sequence import DatasetSequence\n",
    "from custom_mse_loss import CustomMSELoss\n",
    "from custom_mae_loss import CustomMAELoss\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "import datetime\n",
    "\n",
    "# Required to save models in HDF5 format\n",
    "# !pip install pyyaml h5py\n",
    "\n",
    "print(tf.__version__)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1-9eIYxmqji0",
    "outputId": "b0cd3416-7d9f-45b6-be9e-3628574f3082",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/"
   ],
   "metadata": {
    "id": "vl7vK8K-FRAM",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "gpu = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu[0], True)"
   ],
   "metadata": {
    "id": "4pdesxL8bdB6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Data"
   ],
   "metadata": {
    "id": "rm6DxG22DaCV",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dataset_path = './dataset_split'\n",
    "train_ds = DatasetSequence(dataset_path, batch_size=32, split='train', image_size=(256, 256))\n",
    "test_ds = DatasetSequence(dataset_path, batch_size=32, split='test', image_size=(256, 256))\n",
    "val_ds = DatasetSequence(dataset_path, batch_size=32, split='val', image_size=(256, 256))"
   ],
   "metadata": {
    "id": "putuBL8nBdiL",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "outputId": "4a53fa20-c8c5-494f-a323-5a98d185fef5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build Model"
   ],
   "metadata": {
    "id": "6I3xwSMuDdHq",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#@title Build Model {vertical-output: true, display-mode: \"form\" }\n",
    "model_name = \"unet4\" #@param {type:\"string\"}\n",
    "depth = 4 #@param {type:\"integer\"}\n",
    "dropout_prob = 0.3 #@param {type:\"number\"}\n",
    "n_filters = 32 #@param {type:\"integer\"}\n",
    "\n",
    "\n",
    "#@markdown ---\n",
    "\n",
    "class Encoder(layers.Layer):\n",
    "\n",
    "  def __init__(self, n_filters=32, name=\"encoder\", dropout_prob=0.3, max_pooling=True, **kwargs):\n",
    "      super(Encoder, self).__init__(name=name, **kwargs)\n",
    "\n",
    "      self.conv1 = tf.keras.layers.Conv2D(n_filters, \n",
    "                3,  \n",
    "                activation='relu',\n",
    "                padding='same',\n",
    "                kernel_initializer='HeNormal')\n",
    "      self.conv2 = tf.keras.layers.Conv2D(n_filters, \n",
    "                3,  \n",
    "                activation='relu',\n",
    "                padding='same',\n",
    "                kernel_initializer='HeNormal')\n",
    "      \n",
    "      self.drop = tf.keras.layers.Dropout(dropout_prob)\n",
    "\n",
    "      self.max_pooling_layer = tf.keras.layers.MaxPooling2D(\n",
    "          pool_size = (2,2),\n",
    "          padding='same')\n",
    "      \n",
    "      self.max_pooling = max_pooling\n",
    "\n",
    "      self.norm = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "\n",
    "  def call(self, inputs, training=False):\n",
    "\n",
    "      conv1 = self.conv1(inputs)\n",
    "      conv2 = self.conv2(conv1)\n",
    "\n",
    "      norm = self.norm(conv2, training=training)\n",
    "\n",
    "      drop = self.drop(norm, training=training)\n",
    "\n",
    "      if self.max_pooling :\n",
    "        next_layer = self.max_pooling_layer(drop)  \n",
    "      else:\n",
    "        next_layer = drop\n",
    "\n",
    "      skip_connection = drop\n",
    "\n",
    "      return next_layer, skip_connection\n",
    "      \n",
    "class Decoder(layers.Layer):\n",
    "\n",
    "    def __init__(self, n_filters=32, name=\"decoder\", **kwargs):\n",
    "        super(Decoder, self).__init__(name=name, **kwargs)\n",
    "\n",
    "        self.up = tf.keras.layers.Conv2DTranspose(\n",
    "                 n_filters,\n",
    "                 (3,3),\n",
    "                 strides=(2,2),\n",
    "                 padding='same')\n",
    "\n",
    "        self.conv1 = tf.keras.layers.Conv2D(n_filters, \n",
    "                 3,  \n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='HeNormal')\n",
    "        \n",
    "        self.conv2 = tf.keras.layers.Conv2D(n_filters, \n",
    "                 3,  \n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='HeNormal')\n",
    "\n",
    "    def call(self, inputs, skip_layer_inputs):\n",
    "\n",
    "        up = self.up(inputs)\n",
    "        merge = tf.keras.layers.concatenate([up, skip_layer_inputs], axis=-1)\n",
    "        conv1 = self.conv1(merge)\n",
    "        conv2 = self.conv2(conv1)\n",
    "\n",
    "        return conv2\n",
    "\n",
    "class Unet(tf.keras.Model):\n",
    "\n",
    "  def __init__(\n",
    "        self,\n",
    "        inputshape = (256, 256, 1),\n",
    "        depth = 4,\n",
    "        dropout_prob = 0.3,\n",
    "        n_filters = 64,\n",
    "        name = \"unet\",\n",
    "        **kwargs\n",
    "    ):\n",
    "    super(Unet, self).__init__(name=name, **kwargs)\n",
    "\n",
    "    self.inputshape = inputshape\n",
    "    self.depth = depth\n",
    "\n",
    "    self.encoders = []\n",
    "    self.decoders = []\n",
    "\n",
    "    self.input_layer = tf.keras.layers.Input(shape=self.inputshape)\n",
    "\n",
    "    for i in range(depth):\n",
    "      self.encoders.append(Encoder(name = 'encoder'+ str(i), n_filters=n_filters * (2**i) , dropout_prob=dropout_prob, max_pooling=True))\n",
    "      self.decoders.append(Decoder(name = 'decoder'+ str(i), n_filters=n_filters * (2**i)))\n",
    "      \n",
    "    self.bottom_layer = Encoder(name = 'bottom', n_filters=n_filters * (2**depth) , dropout_prob=dropout_prob, max_pooling=False)\n",
    "\n",
    "    self.outConv = tf.keras.layers.Conv2D(\n",
    "                 2, \n",
    "                 3,\n",
    "                 name='output_conv',\n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='HeNormal')\n",
    "\n",
    "  def call(self, inputs, training=False, mask=None):\n",
    "\n",
    "    skips = []\n",
    "\n",
    "    encoder = self.input_layer(inputs)\n",
    "\n",
    "    for i in range(self.depth):\n",
    "      encoder, skip = self.encoders[i](encoder, training=training)\n",
    "      skips.append(skip)\n",
    "\n",
    "    decoder, _ = self.bottom_layer(encoder, training=training)\n",
    "\n",
    "    for i in reversed(range(self.depth)):\n",
    "      decoder = self.decoders[i](decoder, skips[i])\n",
    "\n",
    "    # How to get 2 layers on the output ? Deep layer of size 2* output image size then cut in 2 ?\n",
    "    prediction = self.outConv(decoder)\n",
    "    output = tf.keras.layers.concatenate([inputs, prediction], axis=-1)\n",
    "    return output\n",
    "\n",
    "  def model(self):\n",
    "        x = tf.keras.layers.Input(shape=self.inputshape)\n",
    "        return Unet(inputs=[x], outputs=self.call(x))\n",
    "\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = Unet(depth=depth, \n",
    "             dropout_prob=dropout_prob, \n",
    "             n_filters=n_filters, \n",
    "             name=model_name)\n",
    "\n",
    "# 2**depth MINIMUM\n",
    "# model.build(input_shape=(None, 256, 256, 1))\n",
    "\n",
    "#Process some data before, build is not enought\n",
    "# tf.keras.utils.plot_model(\n",
    "#     model.model(),\n",
    "#     to_file='model.png',\n",
    "#     show_shapes=True,\n",
    "#     show_dtype=True,\n",
    "#     show_layer_names=True,\n",
    "#     rankdir='TB',\n",
    "#     expand_nested=True,\n",
    "#     dpi=96,\n",
    "#     layer_range=None,\n",
    "#     show_layer_activations=True\n",
    "# )\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# Don't ask\n",
    "# tf.keras.utils.plot_model(\n",
    "#     model.model(),\n",
    "#     to_file='model.png',\n",
    "#     show_shapes=True,\n",
    "#     show_dtype=True,\n",
    "#     show_layer_names=True,\n",
    "#     rankdir='TB',\n",
    "#     expand_nested=True,\n",
    "#     dpi=96,\n",
    "#     layer_range=None,\n",
    "#     show_layer_activations=True\n",
    "# )"
   ],
   "metadata": {
    "id": "AazNzL6WC9uE",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "c69d7ace-5130-43a2-8906-24352f677d57",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Learning"
   ],
   "metadata": {
    "id": "CFXMZcGkFrTD",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#@title Parameters { run: \"auto\", display-mode: \"form\" }\n",
    "\n",
    "#@markdown ### Learning Parameters\n",
    "batch_size = 32 #@param {type:\"integer\"}\n",
    "epochs = 5 #@param {type:\"integer\"}\n",
    "learning_rate = 1e-3 #@param {type:\"number\"}\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### Loading Model\n",
    "load_model = False #@param {type:\"boolean\"}\n",
    "load_latest = True #@param {type:\"boolean\"}\n",
    "load_path = \"learning1/unet.ckpt\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### Saving Model\n",
    "save_model = True #@param {type:\"boolean\"}\n",
    "checkpoint_path = \"learning1/unet.ckpt\" #@param {type:\"string\"}\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "save_every_x_epochs = 5 #@param {type:\"integer\"}\n",
    "\n",
    "callbacks = []"
   ],
   "metadata": {
    "id": "sY4UKyaY6OGy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Start learning"
   ],
   "metadata": {
    "id": "gUamXr1linmg",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Load saved weights\n",
    "if load_model:\n",
    "  if load_latest:\n",
    "    load_path = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "  model.load_weights(load_path)"
   ],
   "metadata": {
    "id": "j5LKoz8Y-BEl",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "loss = CustomMAELoss(alpha=1.0)\n",
    "# loss_metric = tf.keras.metrics.Mean()\n",
    "loss_metric = ['accuracy']\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=loss_metric)"
   ],
   "metadata": {
    "id": "Le1VHnMQ5ssu",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 38,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if save_model:\n",
    "  #Save the model\n",
    "\n",
    "  # Create a callback that saves the model's weights\n",
    "  save_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                  save_weights_only=True,\n",
    "                                                  verbose=1,\n",
    "                                                  save_freq=save_every_x_epochs*batch_size) #Every 5 epoch\n",
    "  callbacks.append(save_callback)"
   ],
   "metadata": {
    "id": "3ZLpbEGm5WDB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Tensor Board callback\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "callbacks.append(tensorboard_callback)"
   ],
   "metadata": {
    "id": "WalFi2OB5iRB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "results = model.fit(\n",
    "          train_ds,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=val_ds,\n",
    "          callbacks=callbacks)"
   ],
   "metadata": {
    "id": "wOEm6yMS5ovp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 39,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling layer \"unet4\" \"                 f\"(type Unet).\n\n'KerasTensor' object is not callable\n\nCall arguments received by layer \"unet4\" \"                 f\"(type Unet):\n  • inputs=tf.Tensor(shape=(32, 256, 256), dtype=float32)\n  • training=False\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [39], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m          \u001B[49m\u001B[43mtrain_ds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m          \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m          \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m          \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_ds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m          \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\python_projects\\assignments_comp_vision\\comp4471_final_project\\venv_final_project_cv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "Cell \u001B[1;32mIn [37], line 126\u001B[0m, in \u001B[0;36mUnet.call\u001B[1;34m(self, inputs, training, mask)\u001B[0m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, mask\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    124\u001B[0m   skips \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m--> 126\u001B[0m   encoder \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput_layer\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    128\u001B[0m   \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdepth):\n\u001B[0;32m    129\u001B[0m     encoder, skip \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoders[i](encoder, training\u001B[38;5;241m=\u001B[39mtraining)\n",
      "\u001B[1;31mTypeError\u001B[0m: Exception encountered when calling layer \"unet4\" \"                 f\"(type Unet).\n\n'KerasTensor' object is not callable\n\nCall arguments received by layer \"unet4\" \"                 f\"(type Unet):\n  • inputs=tf.Tensor(shape=(32, 256, 256), dtype=float32)\n  • training=False\n  • mask=None"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Show results"
   ],
   "metadata": {
    "id": "jGfwMix-GSja",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%tensorboard --logdir logs/fit"
   ],
   "metadata": {
    "id": "HMF7lzfOGUl2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#show graphs"
   ],
   "metadata": {
    "id": "1L1BBZ-yCjfW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}